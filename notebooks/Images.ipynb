{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe854d5-930c-4b9b-ba5f-c0eed6b76469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmeyer/miniconda3/envs/ood/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import os\n",
    "from ood_detection.classification_utils import full_classification\n",
    "from ood_detection.config import Config\n",
    "import torchvision\n",
    "\n",
    "from datasets import caltech, flowers102, caltech_cub, svhn, pneumonia, imagenet, cifar, lsun, corruptions\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "\n",
    "def plot_pairs(dataset, seconds = 2.):\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)    \n",
    "    for img, label in dataloader:\n",
    "        img = img.squeeze().permute(1,2,0)\n",
    "        print(f\"Label is: {label}, a {dataset.idx_to_class[int(label)]}\")\n",
    "        display.display(plt.imshow(img))\n",
    "        plt.show()\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(seconds)\n",
    "class ShapePrinter:\n",
    "    def __call__(self, sample):\n",
    "        try:\n",
    "            print(sample.shape)\n",
    "        except:\n",
    "            print(f\"no shape attribute, size: {sample.size}\")\n",
    "        return sample\n",
    "    \n",
    "class ToInter:\n",
    "    def __call__(self, sample):\n",
    "        return sample / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9ff566-e413-4cd2-a3a0-6a1d87d90d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Config.DATAPATH\n",
    "train = False\n",
    "clip_model, transform_clip = clip.load(Config.VISION_MODEL)\n",
    "corruption_dict = corruptions.Corruptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b09bf75-87a9-440c-8733-ffaef008152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(c, sev):\n",
    "    transforms = []\n",
    "    for trans in transform_clip.transforms[:-2]:\n",
    "        transforms.append(trans)\n",
    "    transforms.append(c(sev))\n",
    "    transforms.append(transform_clip.transforms[-2])\n",
    "    transforms.append(ToInter())\n",
    "    return Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9583a381-edc7-4f6c-a1cf-395fde1d0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets.lsun:LSUN already downloaded\n",
      "WARNING:datasets.lsun:SETTING TARGETS ONLY FOR VALIDATION SET\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m lsun\u001b[38;5;241m.\u001b[39mOodLSUN(data_path, transform\u001b[38;5;241m=\u001b[39mcustom_transform, train \u001b[38;5;241m=\u001b[39m train)\n\u001b[1;32m     13\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (image, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseverity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39midx_to_class[\u001b[38;5;28mint\u001b[39m(target)])\n",
      "File \u001b[0;32m~/miniconda3/envs/ood/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ood/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ood/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ood/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/c/users/fmeyer/git/ood-detection/src/datasets/lsun.py:196\u001b[0m, in \u001b[0;36mLSUN.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n\u001b[0;32m--> 196\u001b[0m img, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, target\n",
      "File \u001b[0;32m/mnt/c/users/fmeyer/git/ood-detection/src/datasets/lsun.py:79\u001b[0m, in \u001b[0;36mLSUNClass.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     76\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(buf)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/ood/lib/python3.8/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/mnt/c/users/fmeyer/git/ood-detection/src/datasets/corruptions.py:127\u001b[0m, in \u001b[0;36mOodTransform.__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    125\u001b[0m     sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(sample)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_shape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/fmeyer/git/ood-detection/src/datasets/corruptions.py:211\u001b[0m, in \u001b[0;36mMotionBlurTransform.transform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    208\u001b[0m c \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m), (\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m8\u001b[39m), (\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m12\u001b[39m), (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m15\u001b[39m)][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseverity \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    210\u001b[0m output \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[0;32m--> 211\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(output, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    212\u001b[0m x \u001b[38;5;241m=\u001b[39m MotionImage(blob\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    214\u001b[0m x\u001b[38;5;241m.\u001b[39mmotion_blur(radius\u001b[38;5;241m=\u001b[39mc[\u001b[38;5;241m0\u001b[39m], sigma\u001b[38;5;241m=\u001b[39mc[\u001b[38;5;241m1\u001b[39m], angle\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m45\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "passing = True\n",
    "\n",
    "for name, corr in corruption_dict.items():\n",
    "    #if name == 'JPEG':\n",
    "    #    passing = False\n",
    "    #    #print(f\"Starting with {name}\")\n",
    "    #if passing:\n",
    "    #    #print(f\"skipping {name}\")\n",
    "    #    continue\n",
    "    for severity in range(1,6):\n",
    "        custom_transform = get_transform(corr, severity)\n",
    "        dataset = lsun.OodLSUN(data_path, transform=custom_transform, train = train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "        for i, (image, target) in enumerate(dataloader):\n",
    "            print(f\"{name}: {severity}\")\n",
    "            print(dataloader.dataset.idx_to_class[int(target)])\n",
    "            plt.figure(figsize = (9,9))\n",
    "            plt.imshow(image.squeeze().permute((1,2,0)))\n",
    "            plt.show()\n",
    "            time.sleep(1)\n",
    "            display.clear_output(wait=True)\n",
    "            if i == 2:\n",
    "                break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071bcce-d6bc-495b-8325-dcd193fd0190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
